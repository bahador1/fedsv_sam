{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models import CNNFashion_Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.options import args_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "def args_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # federated arguments (Notation for the arguments followed from paper)\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help=\"number of rounds of training\")\n",
    "    parser.add_argument('--num_users', type=int, default=100,\n",
    "                        help=\"number of users: K\")\n",
    "    parser.add_argument('--frac', type=float, default=0.1,\n",
    "                        help='the fraction of clients: C')\n",
    "    parser.add_argument('--local_ep', type=int, default=5,\n",
    "                        help=\"the number of local epochs: E\")\n",
    "    parser.add_argument('--local_bs', type=int, default=10,\n",
    "                        help=\"local batch size: B\")\n",
    "    parser.add_argument('--bs', type=int, default=128, help='batch size')\n",
    "    parser.add_argument('--lr', type=float, default=0.01,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5,\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "\n",
    "    # model arguments\n",
    "    parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "    parser.add_argument('--kernel_num', type=int, default=9,\n",
    "                        help='number of each kind of kernel')\n",
    "    parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "                        help='comma-separated kernel size to \\\n",
    "                        use for convolution')\n",
    "    parser.add_argument('--num_channels', type=int, default=1, help=\"number \\\n",
    "                        of channels of imgs\")\n",
    "    parser.add_argument('--norm', type=str, default='batch_norm',\n",
    "                        help=\"batch_norm, layer_norm, or None\")\n",
    "    parser.add_argument('--num_filters', type=int, default=32,\n",
    "                        help=\"number of filters for conv nets -- 32 for \\\n",
    "                        mini-imagenet, 64 for omiglot.\")\n",
    "    parser.add_argument('--max_pool', type=str, default='True',\n",
    "                        help=\"Whether use max pooling rather than \\\n",
    "                        strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    parser.add_argument('--dataset', type=str, default='cifar', help=\"name of dataset\")\n",
    "    parser.add_argument('--num_classes', type=int, default=10, help=\"number of classes\")\n",
    "    parser.add_argument('--gpu_id', default=0, help=\"To use cuda, set \\\n",
    "                        to a specific GPU ID. Default set to use CPU.\")\n",
    "    parser.add_argument('--gpu', default=None, help=\"To use cuda, set \\\n",
    "                            to a specific GPU ID. Default set to use CPU.\")\n",
    "    parser.add_argument('--optimizer', type=str, default='sgd', help=\"type \\\n",
    "                        of optimizer\")\n",
    "    parser.add_argument('--iid', type=int, default=0,\n",
    "                        help='Default set to IID. Set to 0 for non-IID.')\n",
    "    parser.add_argument('--unequal', type=int, default=0,\n",
    "                        help='whether to use unequal data splits for  \\\n",
    "                        non-i.i.d setting (use 0 for equal splits)')\n",
    "    parser.add_argument('--stopping_rounds', type=int, default=10,\n",
    "                        help='rounds of early stopping')\n",
    "    parser.add_argument('--verbose', type=int, default=1, help='verbose')\n",
    "    parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "    parser.add_argument('--gamma_sv', type=float, default=0.3, help='SV update gamma')\n",
    "    parser.add_argument('--gamma_ts',type=float, default=0.1,help='decay of TS')\n",
    "    parser.add_argument('--gamma_avg', type=int, default=1, help='init avg gamma')\n",
    "    parser.add_argument('--beta_avg', type=int, default=1, help='init avg beta')\n",
    "    '''\n",
    "        0 - 0_NonIID\n",
    "        1 - 2_LabelNoise\n",
    "        2 - 4_DataNoise\n",
    "        3 - 5_GradientNoise\n",
    "        4 - RandomAttack\n",
    "    '''\n",
    "    parser.add_argument('--noise', type=int, default=0, help='init avg beta')\n",
    "    parser.add_argument('--noiselevel', type=float, default=0, help='gradient noiselevel')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args_parser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = CNNFashion_Mnist(args=args)\n",
    "# global_model = CNNMnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNFashion_Mnist(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = global_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14128/2388854677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(\"original weight = \", w[i][key])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "noise = torch.tensor(np.random.normal(0, 0.2, w[i][key].shape))\n",
    "noise = noise.to(torch.float32)\n",
    "noise = noise.to(args.device)\n",
    "# print(\"original weight = \", w[i][key])\n",
    "w[i][key] += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in w.keys():\n",
    "    print(key)\n",
    "    print(w[key].shape)\n",
    "    print(w[key].dtype)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2], dtype = torch.float32)\n",
    "y  = torch.tensor([1,2], dtype = torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"running_mean\" in \"layer1.1.running_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"i = {i}\")\n",
    "    for j in range(20):\n",
    "        \n",
    "        if j==10: \n",
    "            break\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bm1/Downloads/projects/ShapleyFL-Robust-Federated-Learning-Based-on-Shapley-Value/ImageClassification/src_opt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AFedSV_fmnist_cnn_E100_N0_gamma0.3_repeat1_cuda:0.txt   fedavgscaled.py\n",
      " AFedSV+.py                                              fedprox.py\n",
      " AFedSV.py                                               fedsv.py\n",
      " AFedSV_simplified.py                                    fed_sv_tanh.txt\n",
      " Afedsv_simplified_scaling1.txt                          rfa.py\n",
      " Afedsv_simplified_scaling.txt                           s-fedavg.py\n",
      " AFedSV-softmax.py                                       Untitled-1.ipynb\n",
      "'fedavg prior.py'                                        \u001b[0m\u001b[01;34mutils\u001b[0m/\n",
      " fedavg.py                                              \u001b[01;34m'utils samin'\u001b[0m/\n",
      " fedavg_sam.py\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bm1/Downloads/projects/ShapleyFL-Robust-Federated-Learning-Based-on-Shapley-Value/ImageClassification\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afedsv_simplified_scaling1.txt  \u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mlogs\u001b[0m/  \u001b[01;34msave\u001b[0m/  \u001b[01;34msave_opt\u001b[0m/  \u001b[01;34msrc_opt\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './save_opt/0_NonIID/FedSV.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14128/2512516447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Repetition [%d] : [%s]\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"%.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "f= open(path, \"a+\")\n",
    "f.writelines(\"Repetition [%d] : [%s]\\n\" % (_ + 1, ', '.join([\"%.4f\" % w for w in [1,2,3]])))\n",
    "f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Repetition [1] : [1.0000, 2.0000, 3.0000]\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Repetition [%d] : [%s]\\n\" % (0 + 1, ', '.join([\"%.4f\" % w for w in [1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0000, 2.0000, 3.0000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([\"%.4f\" % w for w in [1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--noise'], dest='noise', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='init avg beta', metavar=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--gamma_ts',type=float, default=0.1,help='decay of TS')\n",
    "parser.add_argument('--gamma_avg', type=int, default=1, help='init avg gamma')\n",
    "parser.add_argument('--beta_avg', type=int, default=1, help='init avg beta')\n",
    "'''\n",
    "    0 - 0_NonIID\n",
    "    1 - 2_LabelNoise\n",
    "    2 - 4_DataNoise\n",
    "    3 - 5_GradientNoise\n",
    "    4 - RandomAttack\n",
    "'''\n",
    "parser.add_argument('--noise', type=int, default=0, help='init avg beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-f'], dest='f', nargs=None, const=None, default=None, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.BatchNorm1d(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0.])),\n",
       "             ('running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0.])),\n",
       "             ('running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('num_batches_tracked', tensor(0))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RANDOM_SEED = 123\n",
    "BATCH_SIZE = 256\n",
    "NUM_HIDDEN_1 = 75\n",
    "NUM_HIDDEN_2 = 45\n",
    "NUM_EPOCHS = 50\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultilayerPerceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes, drop_proba, \n",
    "                 num_hidden_1, num_hidden_2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.my_network = torch.nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(num_features, num_hidden_1, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_hidden_1),\n",
    "            torch.nn.ReLU(),\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(num_hidden_1, num_hidden_2, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_hidden_2),\n",
    "            torch.nn.ReLU(),\n",
    "            # output layer\n",
    "            torch.nn.Linear(num_hidden_2, num_classes)\n",
    "        )\n",
    "           \n",
    "    def forward(self, x):\n",
    "        logits = self.my_network(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultilayerPerceptron(num_features=28*28,\n",
    "                             num_hidden_1=NUM_HIDDEN_1,\n",
    "                             num_hidden_2=NUM_HIDDEN_2,\n",
    "                             drop_proba=0.5,\n",
    "                             num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bm1/miniconda3/envs/toefinder/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(torch.tensor(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2.0\n",
    "import sys, os\n",
    "\n",
    "cur_path = os.path.abspath(os.path.dirname(__file__))\n",
    "sys.path.insert(0, cur_path + \"/..\")\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src_opt.utils.options import args_parser\n",
    "from src_opt.utils.update import LocalUpdate, test_inference\n",
    "from src_opt.utils.models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar\n",
    "from src_opt.utils.Shapley import Shapley\n",
    "from src_opt.utils.CEXPIX import arms_selection\n",
    "from src_opt.utils.tools import get_dataset, average_weights, exp_details, avgSV_baseline, softmax, unbiased_selection, \\\n",
    "    add_gradient_noise, add_random_gradient, get_noiseword\n",
    "\n",
    "args = args_parser()\n",
    "exp_details(args)\n",
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "\n",
    "\n",
    "def solver(gamma):\n",
    "    start_time = time.time()\n",
    "    # define paths\n",
    "    logger = SummaryWriter('../logs')\n",
    "\n",
    "    # if args.gpu_id:\n",
    "    #     torch.cuda.set_device(args.gpu_id)\n",
    "    # device = 'cuda' if args.gpu else 'cpu'\n",
    "\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != None else 'cpu')\n",
    "\n",
    "    # load dataset and user groups\n",
    "    train_dataset, valid_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "\n",
    "    # BUILD MODEL\n",
    "    if args.model == 'cnn':\n",
    "        # Convolutional neural netork\n",
    "        if args.dataset == 'mnist':\n",
    "            global_model = CNNMnist(args=args)\n",
    "        elif args.dataset == 'fmnist':\n",
    "            global_model = CNNFashion_Mnist(args=args)\n",
    "        elif args.dataset == 'cifar':\n",
    "            global_model = CNNCifar(args=args)\n",
    "\n",
    "    elif args.model == 'mlp':\n",
    "        # Multi-layer perceptron\n",
    "        img_size = train_dataset[0][0].shape\n",
    "        len_in = 1\n",
    "        for x in img_size:\n",
    "            len_in *= x\n",
    "            global_model = MLP(dim_in=len_in, dim_hidden=64,\n",
    "                               dim_out=args.num_classes)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    # Set the model to train and send it to device.\n",
    "    global_model = global_model.to(args.device)\n",
    "    global_model.train()\n",
    "\n",
    "    # copy weights\n",
    "    global_weights = global_model.state_dict()\n",
    "    original_weights = copy.copy(global_weights)\n",
    "    # Training\n",
    "    train_loss, train_accuracy = [], []\n",
    "    allAcc_list = []\n",
    "    print_every = 2\n",
    "    init_acc = 0\n",
    "\n",
    "    # attack\n",
    "    attack_epochs = [21, 30] \n",
    "    targeted_clients =[2]\n",
    "    \n",
    "    global_shapley = np.array([0.5 for _ in range(args.num_users)])\n",
    "    cnt_clients = np.ones(args.num_users)\n",
    "    # The prior probability of each arm been selected in one round\n",
    "    probabilities = np.array([args.frac for _ in range(args.num_users)])\n",
    "    normal_shapley = np.array([1 / args.num_users for _ in range(args.num_users)])\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        local_weights, local_losses = [], []\n",
    "        print(f'\\n | Global Training Round : {epoch + 1} |\\n')\n",
    "\n",
    "        global_model.train()\n",
    "        m = max(int(args.frac * args.num_users), 1)\n",
    "        idxs_users = unbiased_selection(probabilities)\n",
    "\n",
    "        # print(\"the number os users is \", len(idxs_users))\n",
    "        # idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "\n",
    "        for idx in idxs_users:\n",
    "            local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
    "                                      idxs=user_groups[idx], logger=logger)\n",
    "            w, loss = local_model.update_weights(\n",
    "                model=copy.deepcopy(global_model).to(args.device), global_round=epoch)\n",
    "            if(epoch in attack_epochs) and (idx in targeted_clients):\n",
    "                    if args.noise == 9:\n",
    "                        print(f\"now the attackers are: {idx} and the epoch is {epoch}\")\n",
    "                        for key in w.keys():\n",
    "                            w[key] = w[key] * 100\n",
    "                    if args.noise == 10:\n",
    "                            for key in w.keys():\n",
    "                                noise = torch.tensor(np.random.normal(0, args.noiselevel, w[i][key].shape))\n",
    "                                noise = noise.to(torch.float32)\n",
    "                                noise = noise.to(args.device)\n",
    "                                # print(\"original weight = \", w[i][key])\n",
    "                                if \"running_mean\" or \"num_batches_tracked\" or \"num_batches_\" in key:\n",
    "                                    break\n",
    "                                w[key] += noise\n",
    "\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(copy.deepcopy(loss))\n",
    "\n",
    "        Fed_sv = Shapley(local_weights, args, global_model, valid_dataset, init_acc)\n",
    "        shapley = Fed_sv.eval_ccshap_stratified(50)\n",
    "        # update estimated Shapley value\n",
    "\n",
    "        weight_shapley = softmax(shapley)\n",
    "        # print(f\"wegiht shapley is {weight_shapley}\")\n",
    "        # Add Gradient Noise\n",
    "        # local_weights = add_gradient_noise(args, local_weights, idxs_users)\n",
    "        global_weights = avgSV_baseline(local_weights, weight_shapley, original_weights)\n",
    "\n",
    "        # update global weights\n",
    "        global_model.load_state_dict(global_weights)\n",
    "        original_weights = copy.copy(global_weights)\n",
    "\n",
    "        loss_avg = sum(local_losses) / len(local_losses)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        # Calculate avg training accuracy over all users at every epoch\n",
    "        list_acc, list_loss = [], []\n",
    "        global_model.eval()\n",
    "        for c in range(args.num_users):\n",
    "            local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
    "                                      idxs=user_groups[c], logger=logger)\n",
    "            acc, loss = local_model.inference(model=global_model)\n",
    "            list_acc.append(acc)\n",
    "            list_loss.append(loss)\n",
    "        train_accuracy.append(sum(list_acc) / len(list_acc))\n",
    "\n",
    "        # print global training loss after every 'i' rounds\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            print(f' \\nAvg Training Stats after {epoch + 1} global rounds:')\n",
    "            print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "            print('Train Accuracy: {:.2f}% \\n'.format(100 * train_accuracy[-1]))\n",
    "        test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "        allAcc_list.append(test_acc)\n",
    "        # print(type(allAcc_list))\n",
    "        print(\" \\nglobal accuracy:{:.2f}%\".format(100 * test_acc))\n",
    "        init_acc = test_acc\n",
    "\n",
    "    # draw(args.epochs, allAcc_list, \"FedAvg 10 100\")\n",
    "    # Test inference after completion of training\n",
    "    test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "\n",
    "    print(f' \\n Results after {args.epochs} global rounds of training:')\n",
    "    print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100 * train_accuracy[-1]))\n",
    "    print(\"|---- Test Accuracy: {:.2f}%\".format(100 * test_acc))\n",
    "\n",
    "    # Saving the objects train_loss and train_accuracy:\n",
    "    # file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'. \\\n",
    "    #     format(args.dataset, args.model, args.epochs, args.frac, args.iid,\n",
    "    #            args.local_ep, args.local_bs)\n",
    "\n",
    "    # with open(file_name, 'wb') as f:\n",
    "    #     pickle.dump([train_loss, train_accuracy], f)\n",
    "\n",
    "    print('\\n Total Run Time: {0:0.4f}'.format(time.time() - start_time))\n",
    "    return test_acc, train_accuracy[-1], allAcc_list\n",
    "\n",
    "\n",
    "def show_avg(acclist):\n",
    "    ans = []\n",
    "    ans.append(np.mean(acclist[17:22]))\n",
    "    ans.append(np.mean(acclist[37:42]))\n",
    "    ans.append(np.mean(acclist[57:62]))\n",
    "    ans.append(np.mean(acclist[77:82]))\n",
    "    ans.append(np.mean(acclist[95:]))\n",
    "    print(ans)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_acc, train_acc = 0, 0\n",
    "    repeat = 1\n",
    "    gamma = args.gamma_sv\n",
    "    noise = args.noise\n",
    "    NoiseWord = get_noiseword()\n",
    "    for _ in range(repeat):\n",
    "        print(\"|---- Repetition {} ----|\".format(_ + 1))\n",
    "        test, train, acc_list = solver(gamma)\n",
    "        test_acc += test\n",
    "        train_acc += train\n",
    "        show_avg(acc_list)\n",
    "        path = './save_opt/{}/FedSV_{}_cnn_E{}_N{}_gamma{}_repeat{}_{}.txt'.format(NoiseWord[noise], args.dataset, args.epochs,\n",
    "                                                                                       args.noiselevel, gamma, repeat, args.device)\n",
    "        f = open(path, \"a+\")\n",
    "        f.writelines(\"Repetition [%d] : [%s]\\n\" % (_ + 1, ', '.join([\"%.4f\" % w for w in acc_list])))\n",
    "        f.flush()\n",
    "        f.close()\n",
    "    print('|---------------------------------')\n",
    "    print(\"|---- Train Accuracy: {:.2f}%\".format(100 * (train_acc / repeat)))\n",
    "    print(\"|---- Test Accuracy: {:.2f}%\".format(100 * (test_acc / repeat)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toefinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
